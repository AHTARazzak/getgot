{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import sys\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup\n",
    "import pyautogui\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.expected_conditions import visibility_of_element_located\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import enchant\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.parse\n",
    "from collections import OrderedDict\n",
    "import names\n",
    "import random\n",
    "import csv\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/a/Desktop/trefacscrapper'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands=['Rick Owens','Damir Doma']\n",
    "owd=os.getcwd()\n",
    "owd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustbrandname(brands):\n",
    "    editbrands=[]\n",
    "    for brand in brands:\n",
    "        editbrand=brand.replace(\" \",\"+\")\n",
    "        editbrands.append(editbrand.lower())\n",
    "    return editbrands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rick+owens', 'damir+doma']\n"
     ]
    }
   ],
   "source": [
    "print(adjustbrandname(brands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getalllinks(brandname,thepage): \n",
    "    url=trefacurl+str(brandname)+\"&key=\"+str(thispage)\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    values = {'name' : names.get_full_name(),\n",
    "        'location' : 'Northampton',\n",
    "        'language' : 'Python' }\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    req = Request(url, headers=headers)\n",
    "    the_page = urlopen(req).read()\n",
    "    pageitemsoup = BeautifulSoup(the_page, 'lxml')\n",
    "    linktags=pageitemsoup.find_all('ul',{'class' : 'itemList l-inlineBox'})[0]\n",
    "    for itematag in linktags.find_all('a'):\n",
    "        if len(itematag['href'])>0:\n",
    "            linklist.append(itematag['href'])           \n",
    "    return(linklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgetpagerange(brandname):\n",
    "    checkpage=True\n",
    "    thepage=1\n",
    "    while checkpage:\n",
    "        url=trefacurl+str(brandname)+\"&key=\"+str(thepage)\n",
    "        user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "        values = {'name' : names.get_full_name(),\n",
    "            'location' : 'Northampton',\n",
    "            'language' : 'Python' }\n",
    "        headers = { 'User-Agent' : user_agent }\n",
    "        req = Request(url, headers=headers)\n",
    "        the_page = urlopen(req).read()\n",
    "        pageitemsoup = BeautifulSoup(the_page, 'lxml')\n",
    "        pagesection=pageitemsoup.find_all('section',{'class' : 'main-pager'})[0]\n",
    "        splitpagesbottom=str(pagesection).split()\n",
    "        if \"</b>\" not in splitpagesbottom[-2]:\n",
    "            thepage+=1\n",
    "        else:\n",
    "            return thepage\n",
    "            checkpagepage=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "#change editbrands to adjustbrandname output\n",
    "for thebrand in ['rick+owens']:\n",
    "    trefacurl=\"https://www.trefac.jp/store/tcpsb/?srchword=\"\n",
    "    linklist=[]\n",
    "    os.chdir(owd)\n",
    "    if not os.path.exists(thebrand):\n",
    "        os.makedirs(thebrand)\n",
    "    os.chdir(thebrand)\n",
    "    if not os.path.exists(thebrand+\"catalogue.csv\"):\n",
    "        append_list_as_row(thebrand+\"catalogue.csv\",[\"Brand\", \"Line\", \"ItemCode\",\"URL\",\"ItemName\",\"Price\",\"Avaliable\",\"Size\",\"Catagories\",\"Condition\",\"Colour\",\"Material\",\"ModelNumber\"])\n",
    "    for page in range(1,getgetpagerange(thebrand)+1):\n",
    "        print(len(getalllinks(thebrand,page)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Brand\", \"Line\", \"ItemCode\",\"URL\",\"ItemName\",\"Price\",\"Avaliable\",\"Size\",\"Catagories\",\"Condition\",\"Colour\",\"Material\",\"ModelNumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "/home/a/Desktop/trefacscrapper/rick+owens\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'item' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-c1c5b95885dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#if not os.path.exists(owd+\"/\"+itemcode):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mitem_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mitem_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mitem_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_page\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item' is not defined"
     ]
    }
   ],
   "source": [
    "linklist=[]\n",
    "print(len(getalllinks('rick+owens',1)))\n",
    "owd=os.getcwd()\n",
    "owd\n",
    "print(owd)\n",
    "for itemurl in linklist:\n",
    "    spliturl=itemurl.split(\"/\")\n",
    "    itemcode=spliturl[-2]\n",
    "    if not os.path.exists(itemcode):\n",
    "        print(itemcode)\n",
    "        os.makedirs(itemcode)\n",
    "        item_req = Request(item, headers=headers)\n",
    "        item_page = urlopen(item_req).read()\n",
    "        item_soup = BeautifulSoup(item_page, 'lxml')\n",
    "        print(item_soup)\n",
    "        #theprice=item_soup.findAll('h1')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
