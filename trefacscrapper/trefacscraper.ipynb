{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import sys\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup\n",
    "import pyautogui\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.expected_conditions import visibility_of_element_located\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import enchant\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.parse\n",
    "from collections import OrderedDict\n",
    "import names\n",
    "import random\n",
    "import csv\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/a/Desktop/trefacscrapper'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thebrands=['Rick Owens','Damir Doma']\n",
    "owd=os.getcwd()\n",
    "owd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustbrandname(brands):\n",
    "    editbrands=[]\n",
    "    for brand in brands:\n",
    "        editbrand=brand.replace(\" \",\"+\")\n",
    "        editbrands.append(editbrand.lower())\n",
    "    return editbrands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getalllinks(brandname,thepage): \n",
    "    url=trefacurl+str(brandname)+\"&key=\"+str(thepage)\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    values = {'name' : names.get_full_name(),\n",
    "        'location' : 'Northampton',\n",
    "        'language' : 'Python' }\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    req = Request(url, headers=headers)\n",
    "    the_page = urlopen(req).read()\n",
    "    pageitemsoup = BeautifulSoup(the_page, 'lxml')\n",
    "    linktags=pageitemsoup.find_all('ul',{'class' : 'itemList l-inlineBox'})[0]\n",
    "    for itematag in linktags.find_all('a'):\n",
    "        if len(itematag['href'])>0:\n",
    "            linklist.append(itematag['href'])           \n",
    "    return(linklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgetpagerange(brandname):\n",
    "    checkpage=True\n",
    "    thepage=1\n",
    "    while checkpage:\n",
    "        url=trefacurl+str(brandname)+\"&key=\"+str(thepage)\n",
    "        user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "        values = {'name' : names.get_full_name(),\n",
    "            'location' : 'Northampton',\n",
    "            'language' : 'Python' }\n",
    "        headers = { 'User-Agent' : user_agent }\n",
    "        req = Request(url, headers=headers)\n",
    "        the_page = urlopen(req).read()\n",
    "        pageitemsoup = BeautifulSoup(the_page, 'lxml')\n",
    "        pagesection=pageitemsoup.find_all('section',{'class' : 'main-pager'})[0]\n",
    "        splitpagesbottom=str(pagesection).split()\n",
    "        if \"</b>\" not in splitpagesbottom[-2]:\n",
    "            thepage+=1\n",
    "        else:\n",
    "            return thepage\n",
    "            checkpagepage=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'themodelis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf60989cd888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m#print(thenameis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m#print(thecolouris)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthemodelis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;31m#print(thematerialis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m#print(theconditionis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'themodelis' is not defined"
     ]
    }
   ],
   "source": [
    "#change editbrands to adjustbrandname output\n",
    "for thebrand in adjustbrandname(thebrands):\n",
    "    trefacurl=\"https://www.trefac.jp/store/tcpsb/?srchword=\"\n",
    "    linklist=[]\n",
    "    os.chdir(owd)\n",
    "    if not os.path.exists(thebrand):\n",
    "        os.makedirs(thebrand)\n",
    "    os.chdir(thebrand)\n",
    "    if not os.path.exists(thebrand+\"catalogue.csv\"):\n",
    "        append_list_as_row(thebrand+\"catalogue.csv\",[\"Brand\", \"ItemCode\",\"URL\",\"ItemName\",\"Price(YEN)\",\"Avaliable\",\"Size\",\"Condition\",\"Colour\",\"Material\",\"ModelNumber\"])\n",
    "    for page in range(1,getgetpagerange(thebrand)+1):\n",
    "        allthelinks=getalllinks(thebrand,page)\n",
    "    owd=os.getcwd()\n",
    "    owd\n",
    "    for itemurl in allthelinks:\n",
    "        spliturl=itemurl.split(\"/\")\n",
    "        itemcode=spliturl[-2]\n",
    "        if not os.path.exists(itemcode):\n",
    "            os.makedirs(itemcode)\n",
    "            user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "            values = {'name' : names.get_full_name(),\n",
    "                'location' : 'Northampton',\n",
    "                'language' : 'Python' }\n",
    "            headers = { 'User-Agent' : user_agent }\n",
    "            item_req = Request(itemurl, headers=headers)\n",
    "            item_page = urlopen(item_req).read()\n",
    "            item_soup = BeautifulSoup(item_page, 'lxml')\n",
    "            theline=item_soup.find_all('span',{'itemprop' : 'name'})[0]\n",
    "            thelineis=str(theline)[str(theline).index('\"name\">')+7:str(theline).index(\"</span\")]\n",
    "            #print(thelineis)\n",
    "            theitemcodeis=itemcode\n",
    "            #print(theitemcodeis)\n",
    "            theitemurlis=itemurl\n",
    "            #print(theitemurlis)\n",
    "            allitemdetail=item_soup.find_all('div',{'class' : 'itemCaption-txt'})[0]\n",
    "            thepricetag=item_soup.find_all('dd',{'class' : 'itemList-price price'})[0]\n",
    "            thesizetag=item_soup.find_all('p',{'class' : 'd-point-before'})[0]\n",
    "            thesizeis=str(thesizetag)[str(thesizetag).index(\":\")+1:str(thesizetag).index(\"</p\")]\n",
    "            #print(thesizeis)\n",
    "            if \"¥\" in str(thepricetag):\n",
    "                thepriceis=str(thepricetag)[str(thepricetag).index(\"¥\")+1:str(thepricetag).index(\"<span\")]\n",
    "            else:\n",
    "                thesalepricetag=item_soup.find_all('dd',{'class' : 'itemList-price priceDown'})[0]\n",
    "                thepriceis=str(thesalepricetag)[str(thesalepricetag).index(\"¥\")+1:str(thesalepricetag).index(\"<span\")]\n",
    "            #print(thepriceis)    \n",
    "            checksoldout=item_soup.find_all('p',{'class' : 'backBtn soldout'})\n",
    "            if len(checksoldout)>0:\n",
    "                avalibis=\"SOLD\"\n",
    "            else:\n",
    "                avalibis=\"AVALIABLE\"\n",
    "            #print(avalibis)\n",
    "            allitemstuffsplit=str(allitemdetail).split(\"\\n\")\n",
    "            for eachline in allitemstuffsplit:\n",
    "                if \"【アイテム名】\" in eachline:\n",
    "                    thenameis=eachline[eachline.index('】')+1:eachline.index('<br')]\n",
    "                if \"【カラー】\" in eachline:\n",
    "                    thecolouris=eachline[eachline.index('】')+1:eachline.index('<br')]\n",
    "                if \"【型番】\" in eachline:\n",
    "                    themodelis=eachline[eachline.index('】')+1:eachline.index('<br')]\n",
    "                else:\n",
    "                    themodelis=\"N/A\"\n",
    "                if \"【素材】\" in eachline:\n",
    "                    thematerialis=eachline[eachline.index('】')+1:eachline.index('<br')]\n",
    "                if \"【状態】\" in eachline:\n",
    "                    theconditionis=eachline[eachline.index('】')+1:eachline.index('<')]                \n",
    "            #print(thenameis)\n",
    "            #print(thecolouris)\n",
    "            #print(themodelis)\n",
    "            #print(thematerialis)\n",
    "            #print(theconditionis)\n",
    "            imageurls=[]\n",
    "            append_list_as_row(thebrand+\"catalogue.csv\",[thelineis, theitemcodeis,theitemurlis,thenameis,thepriceis,avalibis,thesizeis,theconditionis,thecolouris,thematerialis,themodelis])\n",
    "            getimagewindow=item_soup.find_all('ul',{'id' : 'thumblist', 'class' : 'clearfix detailimg'})[0]\n",
    "            for getimageurl in getimagewindow.find_all('a'):\n",
    "                imageurls.append(str(getimageurl)[str(getimageurl).index('largeimage:')+13:str(getimageurl).index('}\">')-1])\n",
    "            for clothingimage in imageurls:\n",
    "                splitimage=clothingimage.split('/')\n",
    "                urllib.request.urlretrieve(str(clothingimage), str(splitimage[-1]))\n",
    "                shutil.move(os.getcwd()+'/'+splitimage[-1], os.getcwd()+'/'+itemcode+'/'+splitimage[-1])\n",
    "                #time.sleep(random.randint(0,2))\n",
    "            print(itemcode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
